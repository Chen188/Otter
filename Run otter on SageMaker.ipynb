{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "246445be-ac62-40e2-8a02-d23d490ace06",
   "metadata": {},
   "source": [
    "使用 Conda_python3 环境即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5942abb3-0822-4f14-8730-d4afd1ccbf6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "sagemaker_default_bucket = sess.default_bucket()\n",
    "\n",
    "account = sess.boto_session.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "region = sess.boto_session.region_name\n",
    "s3_bkt = sagemaker.Session().default_bucket()\n",
    "s3_bkt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8aac4f-c035-4be3-b402-8d1f2f44b82d",
   "metadata": {},
   "source": [
    "## Prepare a docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0804458b-3e55-431a-8d99-bef6df847feb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile Dockerfile\n",
    "## You should change below region code to the region you used\n",
    "From 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:2.0.1-gpu-py310-cu118-ubuntu20.04-sagemaker \n",
    "\n",
    "## Install packages needed in this NLP example\n",
    "RUN pip install transformers==4.31.0 wandb==0.15.8 peft==0.4.0 \\\n",
    "    braceexpand==0.1.7 einops_exts==0.0.4 webdataset==0.2.48 \\\n",
    "    orjson==3.9.5 ijson==3.2.3 yajl==0.3.5 sentencepiece==0.1.99 \n",
    "\n",
    "RUN apt update && apt install libyajl2 -y\n",
    "\n",
    "RUN wget https://github.com/peak/s5cmd/releases/download/v2.2.1/s5cmd_2.2.1_linux_amd64.deb && \\\n",
    "    dpkg -i s5cmd_2.2.1_linux_amd64.deb && rm s5cmd_2.2.1_linux_amd64.deb\n",
    "\n",
    "ENV LANG=C.UTF-8\n",
    "ENV PYTHONUNBUFFERED=TRUE\n",
    "ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
    "\n",
    "## Make all local GPUs visible\n",
    "ENV NVIDIA_VISIBLE_DEVICES=\"all\"\n",
    "\n",
    "## enabel EFA\n",
    "# ENV FI_PROVIDER=\"efa\"\n",
    "# ENV NCCL_PROTO=simple\n",
    "# ENV FI_EFA_USE_DEVICE_RDMA=1\n",
    "\n",
    "# ENV NCCL_LAUNCH_MODE=\"PARALLEL\"\n",
    "# ENV NCCL_NET_SHARED_COMMS=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07002b8f-713b-438d-a2be-d46753610c95",
   "metadata": {},
   "source": [
    "### ECR Login (Must run before docker build)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2af82e-201b-4440-a403-eeafd486202d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## You should change below region code to the region you used, and \n",
    "!aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-east-1.amazonaws.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19dfba7-c0da-4fa9-b284-39939ab1e524",
   "metadata": {},
   "source": [
    "### Build image and push to ECR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac788d5-7605-4d05-ae72-e69f8bc8b375",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## define repo name, should contain *sagemaker* in the name\n",
    "repo_name = \"sagemaker-hf-accelerate-otter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b52a52d-f4a5-4320-8b79-98a0f108d288",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%script env repo_name=$repo_name bash\n",
    "\n",
    "#!/usr/bin/env bash\n",
    "\n",
    "# This script shows how to build the Docker image and push it to ECR to be ready for use\n",
    "# by SageMaker.\n",
    "\n",
    "# The argument to this script is the image name. This will be used as the image on the local\n",
    "# machine and combined with the account and region to form the repository name for ECR.\n",
    "# The name of our algorithm\n",
    "algorithm_name=${repo_name}\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "aws ecr get-login-password --region ${region}|docker login --username AWS --password-stdin ${fullname}\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a72bd5c-ca0e-4218-a1e4-6e8b1f5c08e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_MODEL_DIR = '/opt/ml/base_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0646e847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile sm-train.py\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import socket\n",
    "import yaml\n",
    "\n",
    "# import sagemaker_ssh_helper\n",
    "# sagemaker_ssh_helper.setup_and_start_ssh()\n",
    "\n",
    "BASE_MODEL_DIR = '/opt/ml/base_model'\n",
    "\n",
    "def download_s5cmd():\n",
    "    os.system('wget -q https://github.com/peak/s5cmd/releases/download/v2.2.1/s5cmd_2.2.1_linux_amd64.deb && \\\n",
    "    dpkg -i s5cmd_2.2.1_linux_amd64.deb && rm s5cmd_2.2.1_linux_amd64.deb')\n",
    "\n",
    "\n",
    "def update_text_config():\n",
    "    file_name = f'{BASE_MODEL_DIR}/OTTER-LLaMA7B-INIT/config.json'\n",
    "    with open(file_name) as f:\n",
    "        model_config = json.loads(f.read())\n",
    "\n",
    "    print(\"updating text config for model OTTER-LLaMA7B-INIT\")\n",
    "    model_config['text_config']['_name_or_path'] = f'{BASE_MODEL_DIR}/llama-7b-hf'\n",
    "    model_config['text_config']['architectures'] = [\"LlamaForCausalLM\"]\n",
    "    # model_config['text_config']['architectures'] = None\n",
    "\n",
    "    with open(file_name, 'w') as f:\n",
    "        json.dump(model_config, f)\n",
    "\n",
    "\n",
    "def download_model():\n",
    "    model_s3_url = os.environ.get('MODEL_S3_BASE')\n",
    "    if len(model_s3_url) == 0:\n",
    "        return\n",
    "\n",
    "    if not model_s3_url.startswith('s3://'):\n",
    "        model_s3_url = 's3://' + model_s3_url\n",
    "\n",
    "    print(f'downloading model from {model_s3_url}')\n",
    "    os.system(f\"mkdir -p {BASE_MODEL_DIR}\")\n",
    "    os.system(f\"s5cmd sync {model_s3_url}/* {BASE_MODEL_DIR}/\")\n",
    "\n",
    "\n",
    "def download_data():\n",
    "    data_s3_url = os.environ.get('DATA_S3_BASE')\n",
    "    if len(data_s3_url) == 0:\n",
    "        return\n",
    "\n",
    "    if not data_s3_url.startswith('s3://'):\n",
    "        data_s3_url = 's3://' + model_s3_url\n",
    "\n",
    "    print(f'downloading trainig data from {data_s3_url}')\n",
    "    os.system(f\"s5cmd sync {data_s3_url}/* /opt/ml/input/data/\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        download_s5cmd()\n",
    "        download_model()\n",
    "        update_text_config()\n",
    "        download_data()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    print(os.system('ls -Rlh /opt/ml/'))\n",
    "\n",
    "    hosts = json.loads(os.environ['SM_HOSTS'])\n",
    "    current_host = os.environ['SM_CURRENT_HOST']\n",
    "    num_gpus = int(os.environ['SM_NUM_GPUS']) # num of gpu in current container\n",
    "    host_rank = int(hosts.index(current_host))\n",
    "    \n",
    "    master = json.loads(os.environ['SM_TRAINING_ENV'])['master_hostname']\n",
    "    master_addr = socket.gethostbyname(master)\n",
    "    \n",
    "    ########################\n",
    "    os.environ['NODE_INDEX'] = str(host_rank)\n",
    "    os.environ['SM_MASTER'] = str(master)\n",
    "    os.environ['SM_MASTER_ADDR'] = str(master_addr)\n",
    "    \n",
    "    os.environ['NCCL_SOCKET_IFNAME'] = 'eth0'\n",
    "    # os.environ['FI_PROVIDER'] = \"efa\"\n",
    "    # os.environ['NCCL_PROTO'] = \"simple\"\n",
    "    # os.environ['FI_EFA_USE_DEVICE_RDMA'] = \"1\"\n",
    "\n",
    "#     os.environ['NCCL_LAUNCH_MODE'] = \"PARALLEL\"\n",
    "#     os.environ['NCCL_NET_SHARED_COMMS'] = \"0\"\n",
    "    #########################\n",
    "\n",
    "    acclerate_file_name = './pipeline/accelerate_configs/accelerate_config_fsdp.yaml'\n",
    "    with open(acclerate_file_name) as f:\n",
    "        doc = yaml.safe_load(f)\n",
    "    doc['machine_rank'] = host_rank\n",
    "    doc['main_process_ip'] = str(master_addr)\n",
    "    doc['num_machines'] = len(hosts)  # how many intances in this training job\n",
    "    doc['num_processes'] = len(hosts) * num_gpus  # how many GPU cards in total\n",
    "    with open(acclerate_file_name, 'w') as f:\n",
    "        yaml.safe_dump(doc, f)\n",
    "    \n",
    "    os.system(f\"accelerate launch --config_file={acclerate_file_name} pipeline/train/instruction_following.py {' '.join(sys.argv[1:])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698b57ad-c7a0-456c-a1cc-00cf042474ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "import boto3\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "\n",
    "region = sess._region_name\n",
    "account_id = sess.account_id()\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac8be47",
   "metadata": {},
   "source": [
    "### 把模型拷贝到S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9774557a-7cd1-40c5-bcad-89d5ee6f54e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install huggingface-hub -Uqq\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "def download_and_push_model_to_s3(model_id, commit_hash, s3_prefix):\n",
    "    local_model_path = Path(f'/home/ec2-user/SageMaker/model/{model_id}')\n",
    "    local_model_path.mkdir(exist_ok=True, parents=True)\n",
    "    model_name = model_id.split('/')[1]\n",
    "    snapshot_download(repo_id=model_id, revision=commit_hash, cache_dir=local_model_path)\n",
    "\n",
    "    model_snapshot_path = list(local_model_path.glob(\"**/snapshots/*\"))[0]\n",
    "\n",
    "    !aws s3 cp --recursive {model_snapshot_path} s3://{s3_bkt}/{s3_prefix}/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546257cf-bec0-4023-b42d-cf0b95c72136",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_and_push_model_to_s3(\"luodian/llama-7b-hf\", \"27f2d847cf30ab1cdbd4a2ad82fc38309cd57257\", \"viture/training/models/luodian/llama-7b-hf\")\n",
    "download_and_push_model_to_s3(\"luodian/OTTER-LLaMA7B-INIT\", \"cc075926603ab1ffdef5f0a7809f84201ec31346\", \"viture/training/models/luodian/OTTER-LLaMA7B-INIT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8bfa93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 复制数据到S3\n",
    "\n",
    "! aws s3 sync ~/SageMaker/Viture/Data/ s3://{s3_bkt}/otter/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda0129a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Notice\n",
    "Before run below code, make sure you have :\n",
    "\n",
    "- Config VPC endpoint for S3, and add related route to below subnet you used\n",
    "- Config VPC NAT Gateway (if you need pip install during the training or download from internet\n",
    "- Add route(0.0.0.0/0 through NAT GW) to route table which is used by below subnet you used\n",
    "- Config security group (MUST if you use p4d/p4de instances)\n",
    "- Add inbound rule, allow all traffic in from the security itself\n",
    "- Add outbound rule, allow all traffic out to the security itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381ea5f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "image_uri = \"{}.dkr.ecr.{}.amazonaws.com/{}:latest\".format(account, region, repo_name)\n",
    "\n",
    "\n",
    "environment = {\n",
    "    # no tailing /\n",
    "    'MODEL_S3_BASE': f's3://{s3_bkt}/otter/training/model',  # The bucket to store pretrained model and fine-tune model\n",
    "    'DATA_S3_BASE': f's3://{s3_bkt}/otter/data',\n",
    "    \"PYTHONPATH\": \".\",  # required for training\n",
    "}\n",
    "\n",
    "hp = {\n",
    "    \"pretrained_model_name_or_path\": f\"{BASE_MODEL_DIR}/OTTER-LLaMA7B-INIT\",\n",
    "    \"mimicit_path\": \"/opt/ml/input/data/MIMIC-IT-Release/VST/VST_instructions.json\",\n",
    "    \"images_path\": \"/opt/ml/input/data/MIMIC-IT-Release/VST/VST.json\",\n",
    "    \"train_config_path\": \"/opt/ml/input/data/MIMIC-IT-Release/VST/VST_train.json\",\n",
    "    \"batch_size\": 1,\n",
    "    \"num_epochs\": 6,\n",
    "    \"run_name\": 'OTTER-LLaMA7B-densecaption',\n",
    "    \"wandb_project\": 'OTTER-LLaMA7B',\n",
    "    \"workers\": 1,\n",
    "    \"lr_scheduler\": \"cosine\",\n",
    "    \"learning_rate\": '1e-5',\n",
    "    \"warmup_steps_ratio\": '0.01',\n",
    "    \"model_name\": \"flamingo\",\n",
    "    \"save_hf_model\": True,\n",
    "    \"offline\": True,\n",
    "}\n",
    "\n",
    "base_job_name = 'viture-otter'\n",
    "\n",
    "instance_type = 'ml.g5.12xlarge'\n",
    "\n",
    "estimator = Estimator(role=role,\n",
    "                      entry_point='sm-train.py',\n",
    "                      source_dir='./',\n",
    "                      base_job_name=base_job_name,\n",
    "                      instance_count=1,\n",
    "                      instance_type=instance_type,\n",
    "                      image_uri=image_uri,\n",
    "                      environment=environment,\n",
    "                      hyperparameters=hp,\n",
    "                    #   subnets=['subnet-56d99b20'], # Should be same vpc with FSx, best to use same subnet with FSx\n",
    "                    #   security_group_ids=['sg-e6c3059f'], # Needed when use FSx\n",
    "                      keep_alive_period_in_seconds=60*30, # Optional to set, Recommend use when debug and fast to relaunch without provision instances and images download, need submit warm pool instances limit increase first\n",
    "                      volume_size = 50,\n",
    "                      disable_profiler=True,\n",
    "                      debugger_hook_config=False,\n",
    "                      wait=False)\n",
    "\n",
    "# estimator.fit({\"MIMIC-IT-Release\": \"s3://xxx\"})\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce43f78-434b-46ef-8b64-cf1efcda4d50",
   "metadata": {},
   "source": [
    "# SM Serving\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49f42f3-ecfc-42e0-8ad9-cc531ea8d0fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "download_and_push_model_to_s3('luodian/OTTER-Image-MPT7B', '6c2012970fcd643c015769a717259597f20e08f6', \"viture/serving/models/luodian/OTTER-Image-MPT7B\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
